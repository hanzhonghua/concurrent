># 1.引子
>            目前，计算机已经是多处理器，性能较之以前已经有了非常大的提高。为了更加充分的提高性能，在执行IO等待操作时，需要让出CPU，让CPU处理其它任务，也就是
>        所谓的分时系统，并发也就跟着出现了。后来出现了多核CPU又有了并行计算，也就是所谓的【分工】。分工之后为了更近一步的提升效率和达到更加灵活的目的，所以
>        就对任务进行了组织编排，也就是对线程的编排，于是线程间就有了通信，于是操作系统就提供了让进程，线程通信的方式-信号量和管程，也就是所谓的【同步/协作】。
>        线程通信时，又带来了新的问题-多线程访问共享变量（安全问题），为了解决这个问题，又对访问共享变量进行串行话，也就是所谓的【互斥】

# 2.原子性，可见性，顺序性 并发Buy的真正源头
>            说到并发问题，都离不开CPU，内存，与IO，CPU主要用来做核心计算，内存用来存储，IO外部资源访问，三者的速度CPU>>>内存>>>>>IO，一个系统，往往都
>        一定会伴随的IO访问，根据水桶原则，单纯的提高CPU效率是提高不了整体计算机系统的效率的。面对这种问题，计算机系统，编译程序都给出了优化。CPU增加了缓存，均衡与内存间的差异。
>        操作系统增加了进程，线程，以用来分时复用CPU，均衡内存与IO设备间的差异，编译程序增加了指令重排序，使得缓存可以更加高效的利用
>    
>        但是，事情往往都不是绝对美好的，并发产生的各种问题，源头也在这里。
>       
>        1.缓存导致的可见性问题
>            一个变量的定义都是在内存里，CPU多核时代，每个CPU都有自己的缓存，当多个线程在不同CPU执行时，就有了多个不同的CPU缓存。举个例子，在内存中
>            定义一个变量，当线程A，B访问它时，首先会将变量的当前值缓存到线程的工作缓存中去，之后线程在操作这个变量时，操作的是自己缓存中的变量，这个
>            操作A，B线程是不可见的。详细来说就是，在内存中定义一个变量i=0；线程A，和线程B都对i进行+1的操作，理想状态最终i的结果是2，但结果很有可能
>            会出现1的情况，建单描述下：就是线程A去读这个变量，发现是0，然后进行+1，可能这个时候线程B读到的变量也是0，也是进行了+1，因为不同线程的
>            工作内存操作时不可见的，所有就有了结果可能是1的情况。
>            java中提供了【volatile】来解决这个可见性的问题，在操作变量时，强制线程去中内存中同步变量的最新值，也就是解决了可见性问题，另外volatile
>            还可以解决的就是指令重排问题，是通过内存屏障来实现的，具体可以看代码的volatile包下的详细说明，另外volatile解决不了原子性问题
>            
>        2.线程切换带来的原子性问题
>            由于IO操作太慢，刚开始的操作系统发明了多进程，就可以一边玩游戏，一边听歌，这就是多进程的功劳。操作系统允许一个进程执行小段时间，例如50ms，
>            过了50ms后，操作系统就会重新选择进程执行，这个50ms被称为【时间片】。如果在一个时间片内，一个进程执行了IO操作，那么该进程就会标记自己休眠，
>            让出CPU，允许操作系统调度其它进程执行，这样一来，效率就上来了。这也是所谓的任务切换，现在说到的任务切换指的是线程切换，在同一个进程内，创建
>            的所有线程是共享内存空间的。Java的并发程序也是基于多线程的，自认也会涉及到任务切换。
>            任务的切换大多是在时间片接受后的，Java这种高级语言程序里一条语句都包含多个【CPU指令】，如count++，包含三个指令：
>            1.将count从主内存读到线程工作内存，2.在工作内存执行+1，3.将count写到主内存
>            操作系统执行任务切换，可以发生在任意一条CPU指令执行完。如果多线程环境下，执行count++，结果往往到不到预期，比如线程A，B，执行count++，当
>            A执行执行到把count=0加载到工作内存的时候，这个时候发生了线程切换，线程B也将count=0加载到了工作内存，这个时候线程A，B都是基于0开始执行++的
>            这个时候，结果往往达不到预期
>            把一个或者多个操作在CPU的执行过程中不会被打断的特性称为原子性。很显然，count++不是原子性操作。CPU保证的原子操作是指令级别的，所有在Java里
>            我们需要手动保证某些操作的原子性，也就是加锁。
>            
>        3.编译优化带来的有序性问题
>            操作系统为了更进一步的提升效率，往往会在不影响程序执行结果的同时会调整程序中语句的执行顺序，如
>            int a=1；
>            int b=2;
>            a++;
>            b++;
>            sout(a+b);
>            如上代码，编译期可能调整代码的执行顺序，可能吧b++执行顺序调整到a++前面执行。java中有一个非常著名的单例模式-双重检索机制，具体见【volatile】
>            示例代码详细讲解

># Java内存模型（JMM）
>        就是用来解决这些问题的，根据以上描述，你会发现可见性问题是由于CPU缓存问题，有序性问题禁止编译器优化即可。但是也会带来新的性能问题，如何在
>        需要的时候禁用，需要程序员写程序时候来控制，JMM只是提供了对应的禁用的语法：volatile，synchronized，Happens-Before原则与final关键字
>        final修饰的变量在编译时期就会放到堆中，并且是不可变的。是可以随便优化的，但是要注意一定要避免【逸出】
>        volatile主要用来实现可见性与指令重排
>        synchronized主要用来解决原子性问题，在【thread包】中详细介绍
>        volatile与Happens-Before会在【volatiledemo包】中详细介绍与代码示例
>
># 安全性，活跃性，性能并发编程中的核心问题
>        并发领域里，需要注意的东西非常多，但总结起来可以分为三点：安全性，活跃性及性能问题
>        
>        1.安全性
>           说到安全性，在Java中，首先能想到的一个话题就是：这个方法不是线程安全的，这个类是线程安全的。。那么，到底什么是线程安全呢？其实就是程序可以
>         按照我们期望的结果进行，这个期望不管是在单线程还是多线程环境下都是满足的。
>           那么，如何才可以写出线程安全的方法/类呢，在上面介绍的原子性，可见性和顺序性是引发并发程序Bug的源头，这么来说线程安全就是让程序避免原子性，
>         可见性及有序性就可以了。那么是不是所有的代码都需要分析下是否存在以上3个问题呢？当然不是，其实只有一种情况：【当存在共享数据并且共享数据会改变，
>         就是说多线程会操作读写这个共享数据】。
>           那么，如果不共享数据或者数据不发生变化，不就解决了并发问题了么，有一些技术也是基于这个理论的，比如：THreadLocal等。但是共享数据在实际场景中
>         是不可避免的。当多个线程访问同一份数据，并且存在多个多个线程同时修改这份数据，如果不加保护措施，那么就会导致并发Bug（【volatiledemo包】【thread包】
>         的代码示例都能说明），也叫做【数据竞争】，通过以上的代码示例，可以看到接口【数据竞争】可以使用锁和无锁工具类。
>           其实伴随的【数据竞争】还有一个其它的问题，就是【竞态条件】，就是指程序的执行接口依赖线程执行的条件，举个例子：
>         【if (状态变量 满足 条件) {执行}；】，多线程环境下，如果这个操作不加任何保护措施的话，很有可能出现并发Bug，线程A判断满足条件开始执行，还没有执行完时
>         线程B也来执行，发现也满足条件也开始执行，如果这个场景出现在银行转账场景中就会出现重复转多转问题，解决的问题也很简单，就是使用互斥，synchronized，Lock等
>         工具都可以保证
>       
>        2.活跃性
>           所谓活跃性问题，就是指某个操作无法执行下去。【死锁】问题就是活跃性的一种，除了【死锁】还有两种情况：【活锁】与【饥饿】，【死锁】一般都是多个线程相互等待，
>        技术上就是这个线程永久【阻塞】了
>           但是有时线程没有发生阻塞，仍然执行不下去了，就是所谓的【活锁】。道理也很简单，举个例子：路上A，B两人相遇，为了不发生碰撞，A往左走，B往右走，结果还是碰头了
>        解决起来也简单，毕竟是人，是有思想的，让几次就可以了。但是在程序里，线程是没有思想的，当多线程遇到这种场景时，很有可能就互相永久的让下去了。解决这个问题的方式
>        也很简单，就是让线程随机等待一个时间段就可以了，这种方案简单有效，知名Raft这样的分布式一致性算法中也用到了它.
>           还有一个问题就是【饥饿】，也就是线程因为无法访问资源而无法执行下去的情况，在CPU非常繁忙的情况下，线程优先级的的线程得到执行的机会就很小了，就可能发生线程
>       【饥饿】，还有就是持有锁的线程执行时间过长，也有可能造成【饥饿】。那么如何解决呢？有些方案：【1.】分配充足资源 【2.】公平锁，公平的分配资源 【3.】避免持有锁的线程长时间执行
>        以上三种方案中，公平锁相对好实现下，因为针对【1】很多时候资源紧缺，还有【3】持有锁的线程执行时间较复杂业务场景也很难缩短

>        3.性能
>           使用锁时候，另一个需要注意的地方就是性能了，因为加锁的代码都是串行执行的。只所以使用多线程编程，主要就是为了提高性能，但是多线程环境下对于安全性考虑时候
>        使用锁，而使用锁又会使得代码串行化，又会拉低性能，所以在写代码时候应尽量减少串行化。关于串行话对性能影响如何判断呢？有一个【阿姆达尔Amdahl定律】：
>        【S= 1/((1-p)+p/n)】。其中 【n】 代表CPU的核数，【p】 代码并行百分比，用单线程执行非锁区代码时间/单线程执行锁区+飞锁区代码执行时间，所以用锁时一定要关注对性能的影响。
>        JUC包下之所以那么多工具类，很大的一部分原因就是提升在某个特定领域的性能。
>           【无锁】，copy - on - write，乐观锁，原子类等，以及Disruptor是一个无锁内存队列，性能也是一级棒
>           减少锁持有时间，使用细粒度锁，读写锁等，这些在【lock】包下会做详细介绍
>           
>          性能中比较关注的一些指标有【吞吐量】，【延迟】，【并发量】，【吞吐量】指单位时间内处理的请求数量，吞吐量越高，性能越好，【延迟】从发起到接收响应的时间间隔，间隔越小
>       性能越好，【并发量】指能同时处理的请求数量，一般情况下，随着并发量增加，延迟也会增加，所以【延迟】这个指标，也是基于【并发量】来说的，比如并发1000时，延迟50ms
